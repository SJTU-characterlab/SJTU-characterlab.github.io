---
title: "A surround video capture and presentation system for preservation of eye-gaze in teleconferencing applications"
collection: publications
category: manuscripts
permalink: /publication/2015-02-01
excerpt: "<br/><img src='/images/A_surround_video_capture_and_presentation_system_for_preservation_of_eye_gaze_in_teleconferencing_applications.png'>"
date: 2015-02-01
venue: 'Presence'
paperurl: 'http://SJTU-characterlab.github.io/files/A_surround_video_capture_and_presentation_system_for_preservation_of_eye_gaze_in_teleconferencing_applications.pdf'
citation: 'Pan, Y., Oyekoya, O., & Steed, A. (2015). A surround video capture and presentation system for preservation of eye-gaze in teleconferencing applications. Presence, 24(1), 24-43.'
---

We propose a new video conferencing system that uses an array of cameras to capture a remote user and then show the video of that person on a spherical display. This telepresence system has two key advantages: (i) it can capture a near-correct image for any potential observer viewing direction because the cameras surround the user horizontally; and (ii) with view-dependent graphical representation on the spherical display, it is possible to tell where the remote user is looking from any viewpoint, whereas flat displays are visible only from the front. As a result, the display can more faithfully represent the gaze of the remote user. We evaluate this system by measuring the ability of observers to accurately judge which targets the actor is gazing at in two experiments. Results from the first experiment demonstrate the effectiveness of the camera array and spherical display system, in that it allows observers at multiple observing positions to accurately tell at which targets the remote user is looking. The second experiment further compared a spherical display with a planar display and provided detailed reasons for the improvement of our system in conveying gaze. We found two linear models for predicting the distortion introduced by misalignment of capturing cameras and the observerâ€™s viewing angles in video conferencing systems. Those models might be able to enable a correction for this distortion in future display configurations.
