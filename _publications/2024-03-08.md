---
title: "Head3D: complete 3D head generation via tri-plane feature distillation"
collection: publications
category: manuscripts
permalink: /publication/2024-03-08
excerpt: "<br/><img src='/images/Head3D_complete_3D_head_generation_via_tri-plane_feature_distillation.png'>"
date: 2024-03-08
venue: 'ACM Transactions on Multimedia Computing, Communications and Applications'
paperurl: 'http://SJTU-characterlab.github.io/files/Head3D_complete_3D_head_generation_via_tri-plane_feature_distillation.pdf'
citation: 'Cheng, Y., Yan, Y., Zhu, W., Pan, Y., Pan, B., & Yang, X. (2024). Head3D: complete 3D head generation via tri-plane feature distillation. ACM Transactions on Multimedia Computing, Communications and Applications, 20(6), 1-20.'
---

Head generation with diverse identities is an important task in computer vision and computer graphics, widely used in multimedia applications. However, current full-head generation methods require a large number of three-dimensional (3D) scans or multi-view images to train the model, resulting in expensive data acquisition costs. To address this issue, we propose Head3D, a method to generate full 3D heads with limited multi-view images. Specifically, our approach first extracts facial priors represented by tri-planes learned in EG3D, a 3D-aware generative model, and then proposes feature distillation to deliver the 3D frontal faces within complete heads without compromising head integrity. To mitigate the domain gap between the face and head models, we present a dual-discriminator to guide the frontal and back head generation. Our model achieves cost-efficient and diverse complete head generation with photo-realistic renderings and high-quality geometry representations. Extensive experiments demonstrate the effectiveness of our proposed Head3D, both qualitatively and quantitatively.
