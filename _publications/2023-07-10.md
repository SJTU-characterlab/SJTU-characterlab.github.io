---
title: "Rendering and Reconstruction Based 3D Portrait Stylization"
collection: publications
category: conferences
permalink: /publication/2023-07-10
excerpt: "<br/><img src='/images/Rendering_and_Reconstruction_Based_3D_Portrait_Stylization.png'>"
date: 2023-07-10
venue: '2023 IEEE International Conference on Multimedia and Expo (ICME)'
paperurl: 'http://SJTU-characterlab.github.io/files/Rendering_and_Reconstruction_Based_3D_Portrait_Stylization.pdf'
citation: 'Li, S., & Pan, Y. (2023, July). Rendering and Reconstruction Based 3D Portrait Stylization. In 2023 IEEE International Conference on Multimedia and Expo (ICME) (pp. 912-917). IEEE.'
---

Both 2D images and 3D models are vital aspects of portrait applications. Existing style transfer methods principally emphasized 2D images, neglecting the urge for 3D style transfer. We propose rendering and reconstruction based 3D portrait stylization. And we present the first geometry-aware stereoscopic image stylization. Our framework requires one content image and one style image to obtain a 3D stylization portrait. In the first step, 3D face reconstruction produces a 3D face model. We excute stereoscopic rendering to the model and reserve the images and parameters. We propose to perform the perspective transformation on one style image to match two content images. Then we use disparity loss to conduct a geometry-aware stereoscopic stylization. Using stereoscopic stylization images, we calculate the 3D stylization portrait using a stereoscopic 3D reconstruction algorithm. Expect for portraits, the framework
applies to models with simple shapes. Extensive experiments demonstrate the validity and robustness of our method.
