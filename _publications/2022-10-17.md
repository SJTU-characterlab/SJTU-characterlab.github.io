---
title: "3DBrushVR: From Virtual Reality Primitives to Complex Manifold Objects"
collection: publications
category: conferences
permalink: /publication/2022-10-17
excerpt: "<br/><img src='/images/3DBrushVR_From_Virtual_Reality_Primitives_to_Complex_Manifold_Objects.png'>"
date: 2022-10-17
venue: '2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)'
paperurl: 'http://SJTU-characterlab.github.io/files/3DBrushVR_From_Virtual_Reality_Primitives_to_Complex_Manifold_Objects.pdf'
citation: 'Zhu, Y., Tang, X., Zhang, J., Pan, Y., Shen, J., & Jin, X. (2022, October). 3DBrushVR: From Virtual Reality Primitives to Complex Manifold Objects. In 2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct) (pp. 423-428). IEEE.'
---

SurfaceBrush and Brush2Model are two systems which enable users to create 3D objects intuitively using a hand-held controller in virtual reality (VR). These state-of-the-art methods either start modeling from dense collections of stroke ribbons drawn by professional artists, or from the most basic point skeletons, line skeletons, and polygon skeletons. Thus, it is very challenging for novices and amateurs to design complex models efficiently. We propose 3D-BrushVR, a novel VR modeling tool that uses volume skeleton-based convolution surfaces. It enables the user to draw with arbitrarily shaped brushes and generate 3D manifold objects by fusing the brushed primitives. Unlike existing VR drawing and modeling tools, our approach can directly take some common but complex objects as primitives, and assemble them using implicit surfaces, thus providing a more flexible and powerful modeling ability. To achieve real-time performance, we introduce a new GPU-based method to calculate the volume fields of the resulting convolution surfaces. We also introduce several specially designed time-varying shaders to render the designed model for a better and more appealing modeling experience. We demonstrate the usability and modeling ability of our 3DBrushVR interface by comparing it with the state-of-the-art methods in an observational study. Experimental results further validate the effectiveness and flexibility of our approach.
